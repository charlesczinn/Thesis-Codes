{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ee56bc6",
   "metadata": {},
   "source": [
    "## Natural Language Semantic Analysis for Processing Antisemitic Incident Data ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecedba1",
   "metadata": {},
   "source": [
    "After October 7, 2023, the Anti-Defamation League changed their methodologies to include anti-Zionist rallies and slogans in their Annual Audit of Antisemitism. This change in methods confounds the data for quantitative analysis. The following code identifies incidents that were included in the dataset using this new methodology in order to flag them for removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee76793f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/thesis/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e97af76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in dataset\n",
    "df = pd.read_csv('data_incidents_nlp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1532099f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 958/958 [02:52<00:00,  5.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# Transform descriptions into embeddings (semantic vectors)\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "emb = model.encode(df[\"description\"].tolist(), show_progress_bar=True)\n",
    "df[\"embedding\"] = emb.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790651b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables for definition\n",
    "X = np.vstack(df[\"embedding\"].values) # All embedding values as X\n",
    "y = df[\"flag_2\"].values # Status as \"flagged\" from inital keyword flagging process performed in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353448be",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_antizion = X[y == 1].mean(axis=0) # The centroid of all embeddings that are flagged\n",
    "C_other   = X[y == 0].mean(axis=0) # Centroid of all other embeddings\n",
    "antizionism_axis = C_other - C_antizion # Initiate axis by subtracting the centroids\n",
    "antizionism_axis = antizionism_axis / np.linalg.norm(antizionism_axis) # Standardize axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604117f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cosine_similarity(X, antizionism_axis.reshape(1, -1)).flatten() # Reshape on single axis by flattening directions\n",
    "df[\"antizionism_score_axis\"] = (scores - scores.min()) / (scores.max() - scores.min()) # Define the antizionism \"score\" for each event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1b5f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run regression just to see, but not particularly useful\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "clr = LogisticRegression(max_iter=500)\n",
    "clr.fit(X_train, y_train)\n",
    "\n",
    "probs_test = clr.predict_proba(X_test)[:, 1]\n",
    "preds_test = clr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61593aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9979516445499483\n",
      "Log loss: 0.03829723179893413\n",
      "Accuracy: 0.9882567849686847\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (roc_auc_score, accuracy_score, log_loss,)\n",
    "\n",
    "print(\"AUC:\", roc_auc_score(y_test, probs_test))\n",
    "print(\"Log loss:\", log_loss(y_test, probs_test))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03852e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV AUC: [0.998238   0.9981301  0.99862848 0.99733894 0.99828181]\n",
      "Mean AUC: 0.9981234654265831\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "auc_scores = cross_val_score(clr, X, y, cv=5, scoring=\"roc_auc\")\n",
    "\n",
    "print(\"CV AUC:\", auc_scores)\n",
    "print(\"Mean AUC:\", auc_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9e6eb71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.49250678975045237)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_shuffled = np.random.permutation(y)\n",
    "cross_val_score(clr, X, y_shuffled, cv=5, scoring=\"roc_auc\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c195ebb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "552   -2.669840\n",
       "752    2.347832\n",
       "158    2.302842\n",
       "683    2.299570\n",
       "536    2.253939\n",
       "203   -2.020877\n",
       "184    2.010700\n",
       "120   -1.982510\n",
       "33    -1.934568\n",
       "343    1.928836\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef = pd.Series(clr.coef_[0]).sort_values(key=abs, ascending=False)\n",
    "\n",
    "coef.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38f3cd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "probs_cv = cross_val_predict(clr, X, y, cv=5, method=\"predict_proba\")[:, 1]\n",
    "\n",
    "df[\"zionism_score_regression\"] = 1 - probs_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574e0172",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = [\"embedding\"]).to_csv(\"data_incidents_nlp.csv\", index=False) # Turn back into .csv, remove embeddings to limit file size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
